{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b9b36a3",
   "metadata": {},
   "source": [
    "# Dataset Recommendation Example ðŸ“Š\n",
    "\n",
    "This notebook demonstrates how to use SciSynth's dataset recommendation system to find relevant datasets for research hypotheses. The system analyzes hypotheses and suggests datasets that could be useful for testing them.\n",
    "\n",
    "## Setup\n",
    "First, let's import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.data_recommender import recommend_datasets, extract_keywords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca1530",
   "metadata": {},
   "source": [
    "## 1. Extract Keywords from Hypotheses\n",
    "\n",
    "Let's start by extracting keywords from some example hypotheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd492a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"Neural networks perform better with larger training datasets\"\n",
    "keywords = extract_keywords(hypothesis)\n",
    "print(\"Extracted Keywords:\")\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb87b91",
   "metadata": {},
   "source": [
    "## 2. Get Dataset Recommendations\n",
    "\n",
    "Now let's get dataset recommendations for multiple hypotheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0c7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = [\n",
    "    \"Neural networks perform better with larger training datasets\",\n",
    "    \"Transformer models excel at natural language understanding tasks\",\n",
    "    \"Deep learning models require significant computational resources\"\n",
    "]\n",
    "\n",
    "recommendations = recommend_datasets(hypotheses)\n",
    "\n",
    "print(\"Dataset Recommendations:\")\n",
    "for rec in recommendations:\n",
    "    print(f\"\\nHypothesis: {rec['hypothesis']}\")\n",
    "    print(\"Recommended Datasets:\")\n",
    "    for dataset in rec['datasets']:\n",
    "        print(f\"- {dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180589a",
   "metadata": {},
   "source": [
    "## 3. Analyze Recommendations\n",
    "\n",
    "Let's create a summary of the recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b26d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary DataFrame\n",
    "summary_data = []\n",
    "for rec in recommendations:\n",
    "    summary_data.append({\n",
    "        'hypothesis': rec['hypothesis'],\n",
    "        'num_datasets': len(rec['datasets']),\n",
    "        'top_dataset': rec['datasets'][0] if rec['datasets'] else 'None'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\nRecommendation Summary:\")\n",
    "print(summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
